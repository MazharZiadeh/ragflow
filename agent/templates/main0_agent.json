{
  "components": {
    "begin": {
      "obj": {
        "component_name": "Begin",
        "params": {
          "message_history_window_size": 13,
          "inputs": {},
          "outputs": {},
          "description": "",
          "max_retries": 0,
          "delay_after_error": 2.0,
          "exception_method": null,
          "exception_default_value": null,
          "exception_goto": null,
          "debug_inputs": {},
          "enable_tips": true,
          "tips": "Please fill up the form",
          "mode": "conversational",
          "prologue": "Hi! I'm your AI assistant with access to a knowledge base. Ask me anything!",
          "enablePrologue": true
        }
      },
      "downstream": [
        "Categorize:QueryRouter"
      ],
      "upstream": []
    },
    "Categorize:QueryRouter": {
      "obj": {
        "component_name": "Categorize",
        "params": {
          "message_history_window_size": 1,
          "inputs": {},
          "outputs": {
            "category_name": {
              "type": "string",
              "value": null
            }
          },
          "description": "",
          "max_retries": 0,
          "delay_after_error": 2.0,
          "exception_method": null,
          "exception_default_value": null,
          "exception_goto": null,
          "debug_inputs": {},
          "llm_id": "phi4:latest@Ollama",
          "sys_prompt": "\nYou are an advanced classification system that categorizes user questions into specific types. Analyze the input question and classify it into ONE of the following categories:\n\n\nHere's description of each category:\n - \n\n---- Instructions ----\n - Consider both explicit mentions and implied context\n - Prioritize the most specific applicable category\n - Return only the category name without explanations\n - Use \"Other\" only when no other category fits\n\n ",
          "prompts": [
            {
              "role": "user",
              "content": "{sys.query}"
            }
          ],
          "max_tokens": 0,
          "temperature": 0.1,
          "top_p": 0.9,
          "presence_penalty": 0,
          "frequency_penalty": 0,
          "output_structure": null,
          "cite": true,
          "visual_files_var": null,
          "category_description": {
            "Conversational": {
              "description": "Greetings, casual chat, thank yous, or questions that don't require knowledge retrieval. Examples: 'Hello', 'How are you?', 'Thanks!', 'What can you do?'",
              "examples": [
                "Hi there",
                "Thank you"
              ],
              "to": [
                "Agent:ConversationalSimple"
              ]
            },
            "Simple_Lookup": {
              "description": "Straightforward factual questions answerable with specific information. Starts with 'What is', 'When is', 'Who is', 'Where is'. No comparison or complex reasoning needed.",
              "examples": [
                "What is machine learning?",
                "Who invented the telephone?"
              ],
              "to": [
                "Agent:SimpleRetrieval"
              ]
            },
            "Complex_Analysis": {
              "description": "Complex queries requiring analysis, comparison, or synthesis across multiple sources. Includes 'How' or 'Why' questions, summaries, comparisons. Triggers comprehensive retrieval.",
              "examples": [
                "Compare supervised and unsupervised learning",
                "Why did the Roman Empire fall?"
              ],
              "to": [
                "Agent:Planner"
              ]
            }
          },
          "query": "sys.query"
        }
      },
      "downstream": [
        "Agent:ConversationalSimple",
        "Agent:SimpleRetrieval",
        "Agent:Planner"
      ],
      "upstream": [
        "begin"
      ]
    },
    "Agent:ConversationalSimple": {
      "obj": {
        "component_name": "Agent",
        "params": {
          "meta": {
            "name": "agent",
            "description": "This is an agent for a specific task.",
            "parameters": {
              "user_prompt": {
                "type": "string",
                "description": "This is the order you need to send to the agent.",
                "default": "",
                "required": true
              },
              "reasoning": {
                "type": "string",
                "description": "Supervisor's reasoning for choosing the this agent. Explain why this agent is being invoked and what is expected of it.",
                "required": true
              },
              "context": {
                "type": "string",
                "description": "All relevant background information, prior facts, decisions, and state needed by the agent to solve the current query. Should be as detailed and self-contained as possible.",
                "required": true
              }
            }
          },
          "message_history_window_size": 12,
          "inputs": {
            "user_prompt": {
              "type": "string",
              "description": "This is the order you need to send to the agent.",
              "default": "",
              "required": true,
              "value": null
            },
            "reasoning": {
              "type": "string",
              "description": "Supervisor's reasoning for choosing the this agent. Explain why this agent is being invoked and what is expected of it.",
              "required": true,
              "value": null
            },
            "context": {
              "type": "string",
              "description": "All relevant background information, prior facts, decisions, and state needed by the agent to solve the current query. Should be as detailed and self-contained as possible.",
              "required": true,
              "value": null
            }
          },
          "outputs": {
            "content": {
              "type": "string",
              "value": null
            }
          },
          "description": "",
          "max_retries": 1,
          "delay_after_error": 2.0,
          "exception_method": null,
          "exception_default_value": null,
          "exception_goto": [],
          "debug_inputs": {},
          "user_prompt": "",
          "reasoning": null,
          "context": null,
          "llm_id": "llama3.2:latest@Ollama",
          "sys_prompt": "You are a friendly, helpful AI assistant. Answer conversational queries, greetings, and general questions directly without needing external knowledge. Be warm, concise, and engaging.",
          "prompts": [
            {
              "content": "{sys.query}",
              "role": "user"
            }
          ],
          "max_tokens": 512,
          "temperature": 0.7,
          "top_p": 0.3,
          "presence_penalty": 0.4,
          "frequency_penalty": 0.7,
          "output_structure": null,
          "cite": false,
          "visual_files_var": null,
          "function_name": "agent",
          "tools": [],
          "mcp": [],
          "max_rounds": 1,
          "frequencyPenaltyEnabled": false,
          "maxTokensEnabled": false,
          "presencePenaltyEnabled": false,
          "temperatureEnabled": true,
          "topPEnabled": false
        }
      },
      "downstream": [
        "Message:ConversationalOutput"
      ],
      "upstream": [
        "Categorize:QueryRouter"
      ]
    },
    "Agent:SimpleRetrieval": {
      "obj": {
        "component_name": "Agent",
        "params": {
          "meta": {
            "name": "agent",
            "description": "This is an agent for a specific task.",
            "parameters": {
              "user_prompt": {
                "type": "string",
                "description": "This is the order you need to send to the agent.",
                "default": "",
                "required": true
              },
              "reasoning": {
                "type": "string",
                "description": "Supervisor's reasoning for choosing the this agent. Explain why this agent is being invoked and what is expected of it.",
                "required": true
              },
              "context": {
                "type": "string",
                "description": "All relevant background information, prior facts, decisions, and state needed by the agent to solve the current query. Should be as detailed and self-contained as possible.",
                "required": true
              }
            }
          },
          "message_history_window_size": 12,
          "inputs": {
            "user_prompt": {
              "type": "string",
              "description": "This is the order you need to send to the agent.",
              "default": "",
              "required": true,
              "value": null
            },
            "reasoning": {
              "type": "string",
              "description": "Supervisor's reasoning for choosing the this agent. Explain why this agent is being invoked and what is expected of it.",
              "required": true,
              "value": null
            },
            "context": {
              "type": "string",
              "description": "All relevant background information, prior facts, decisions, and state needed by the agent to solve the current query. Should be as detailed and self-contained as possible.",
              "required": true,
              "value": null
            }
          },
          "outputs": {
            "content": {
              "type": "string",
              "value": null
            }
          },
          "description": "",
          "max_retries": 2,
          "delay_after_error": 2.0,
          "exception_method": null,
          "exception_default_value": null,
          "exception_goto": [],
          "debug_inputs": {},
          "user_prompt": "",
          "reasoning": null,
          "context": null,
          "llm_id": "qwen2.5:32b@Ollama",
          "sys_prompt": "You are a precise Retrieval Assistant. Your sole objective is to answer the user's question using ONLY the provided context.\n### CONSTRAINTS:\n1. **Source Grounding:** If the answer isn't in the context, state exactly what is missing rather than saying \"I don't know.\"\n2. **Directness:** Do not use filler phrases like \"Based on the documents provided...\" Jump straight to the facts.\n3. **Citation Format:** Every factual claim must be followed by: **[Doc: document_name, Page: X]**.\n4. **No Assumptions:** Do not use outside knowledge. If the context says the sky is green, the sky is green.\n### TONE:\nProfessional, objective, and concise.",
          "prompts": [
            {
              "content": "=== RETRIEVED DOCUMENTS FROM KNOWLEDGE BASE ===\n{Retrieval_Simple@formalized_content}\n=== END OF RETRIEVED DOCUMENTS ===\n>>> CRITICAL: You have NO knowledge except what appears above in RETRIEVED DOCUMENTS <\n**User Question:** {sys.query}\n**Your Task:**\n1. Search ONLY the retrieved documents above for the answer\n2. Extract facts ONLY from the retrieved content\n3. Use format: **[Doc: document_name, Page: X]** for citations\n4. Cite EVERY fact immediately after stating it\n5. If not in retrieved documents above, say: \"This information is not in my knowledge base\"\n**Answer using ONLY the retrieved documents:**",
              "role": "user"
            }
          ],
          "max_tokens": 2048,
          "temperature": 0.4,
          "top_p": 0.3,
          "presence_penalty": 0.4,
          "frequency_penalty": 0.7,
          "output_structure": null,
          "cite": true,
          "visual_files_var": null,
          "function_name": "agent",
          "tools": [
            {
              "component_name": "Retrieval",
              "id": "Retrieval:SimpleKBSearch",
              "name": "Retrieval_Simple",
              "params": {
                "cross_languages": [],
                "kb_ids": [
                  "6f357bd7f45f11f085b53ae7a67b446b"
                ],
                "keywords_similarity_weight": 0.3,
                "meta_data_filter": {},
                "outputs": {
                  "chunks": {
                    "value": null
                  },
                  "metadata": {
                    "value": null
                  }
                },
                "rerank_id": "",
                "retrieval_from": "dataset",
                "similarity_threshold": 0.1,
                "toc_enhance": true,
                "top_k": 1024,
                "top_n": 8,
                "use_kg": true
              }
            }
          ],
          "mcp": [],
          "max_rounds": 1,
          "frequencyPenaltyEnabled": false,
          "maxTokensEnabled": false,
          "presencePenaltyEnabled": false,
          "temperatureEnabled": true,
          "topPEnabled": false
        }
      },
      "downstream": [
        "Message:SimpleOutput"
      ],
      "upstream": [
        "Categorize:QueryRouter"
      ]
    },
    "Agent:Planner": {
      "obj": {
        "component_name": "Agent",
        "params": {
          "meta": {
            "name": "agent",
            "description": "This is an agent for a specific task.",
            "parameters": {
              "user_prompt": {
                "type": "string",
                "description": "This is the order you need to send to the agent.",
                "default": "",
                "required": true
              },
              "reasoning": {
                "type": "string",
                "description": "Supervisor's reasoning for choosing the this agent. Explain why this agent is being invoked and what is expected of it.",
                "required": true
              },
              "context": {
                "type": "string",
                "description": "All relevant background information, prior facts, decisions, and state needed by the agent to solve the current query. Should be as detailed and self-contained as possible.",
                "required": true
              }
            }
          },
          "message_history_window_size": 1,
          "inputs": {
            "user_prompt": {
              "type": "string",
              "description": "This is the order you need to send to the agent.",
              "default": "",
              "required": true,
              "value": null
            },
            "reasoning": {
              "type": "string",
              "description": "Supervisor's reasoning for choosing the this agent. Explain why this agent is being invoked and what is expected of it.",
              "required": true,
              "value": null
            },
            "context": {
              "type": "string",
              "description": "All relevant background information, prior facts, decisions, and state needed by the agent to solve the current query. Should be as detailed and self-contained as possible.",
              "required": true,
              "value": null
            }
          },
          "outputs": {
            "content": {
              "type": "string",
              "value": null
            }
          },
          "description": "",
          "max_retries": 1,
          "delay_after_error": 2.0,
          "exception_method": null,
          "exception_default_value": null,
          "exception_goto": [],
          "debug_inputs": {},
          "user_prompt": "",
          "reasoning": null,
          "context": null,
          "llm_id": "phi4:latest@Ollama",
          "sys_prompt": "You are a query planning agent for a RAG system. Break down complex queries into focused sub-questions and determine the optimal retrieval strategy.\n\nYour output helps the retrieval system find the most relevant information.",
          "prompts": [
            {
              "content": "Analyze this query and create a retrieval plan:\n\n**Query:** {sys.query}\n\nProvide:\n1. 1-3 focused sub-questions (if query is multi-faceted)\n2. Key search terms and entities\n3. Retrieval strategy recommendation\n\nBe concise - 3-4 sentences total.",
              "role": "user"
            }
          ],
          "max_tokens": 512,
          "temperature": 0.2,
          "top_p": 0.3,
          "presence_penalty": 0.4,
          "frequency_penalty": 0.7,
          "output_structure": null,
          "cite": false,
          "visual_files_var": null,
          "function_name": "agent",
          "tools": [],
          "mcp": [],
          "max_rounds": 1,
          "frequencyPenaltyEnabled": false,
          "maxTokensEnabled": false,
          "presencePenaltyEnabled": false,
          "temperatureEnabled": true,
          "topPEnabled": false
        }
      },
      "downstream": [
        "Agent:AdvancedRetrieval"
      ],
      "upstream": [
        "Categorize:QueryRouter"
      ]
    },
    "Agent:AdvancedRetrieval": {
      "obj": {
        "component_name": "Agent",
        "params": {
          "meta": {
            "name": "agent",
            "description": "This is an agent for a specific task.",
            "parameters": {
              "user_prompt": {
                "type": "string",
                "description": "This is the order you need to send to the agent.",
                "default": "",
                "required": true
              },
              "reasoning": {
                "type": "string",
                "description": "Supervisor's reasoning for choosing the this agent. Explain why this agent is being invoked and what is expected of it.",
                "required": true
              },
              "context": {
                "type": "string",
                "description": "All relevant background information, prior facts, decisions, and state needed by the agent to solve the current query. Should be as detailed and self-contained as possible.",
                "required": true
              }
            }
          },
          "message_history_window_size": 12,
          "inputs": {
            "user_prompt": {
              "type": "string",
              "description": "This is the order you need to send to the agent.",
              "default": "",
              "required": true,
              "value": null
            },
            "reasoning": {
              "type": "string",
              "description": "Supervisor's reasoning for choosing the this agent. Explain why this agent is being invoked and what is expected of it.",
              "required": true,
              "value": null
            },
            "context": {
              "type": "string",
              "description": "All relevant background information, prior facts, decisions, and state needed by the agent to solve the current query. Should be as detailed and self-contained as possible.",
              "required": true,
              "value": null
            }
          },
          "outputs": {
            "content": {
              "type": "string",
              "value": null
            }
          },
          "description": "",
          "max_retries": 2,
          "delay_after_error": 2.0,
          "exception_method": null,
          "exception_default_value": null,
          "exception_goto": [],
          "debug_inputs": {},
          "user_prompt": "",
          "reasoning": null,
          "context": null,
          "llm_id": "qwen2.5:32b@Ollama",
          "sys_prompt": "You are an expert research assistant with access to a comprehensive knowledge base.\n\n## YOUR EXPERTISE:\nYou excel at answering complex, multi-faceted questions by synthesizing information from multiple sources with DETAILED CITATIONS.\n\n## CRITICAL RULES:\n1. The retrieval system has found relevant documents - TRUST and USE them\n2. Information may be distributed across multiple chunks - COMBINE them intelligently\n3. Look for connections, patterns, and relationships in the retrieved content\n4. The answer IS in the context - it may require synthesis but it's there\n5. Use semantic understanding - answers may be phrased differently than the question\n6. Be thorough - complex questions deserve comprehensive answers\n\n## CITATION FORMAT (MANDATORY):\nFor EVERY factual statement, use this format:\n- **[Doc: {document_name}, Page: {page_number}, Section: {section_name}]**\n- OR **[Source: {chunk_id}]** if full metadata unavailable\n- Place citations immediately after each claim\n- Use multiple citations when synthesizing from multiple sources\n- Include as much source metadata as available\n\n## ANSWER STRUCTURE:\n- Start with a direct answer to the main question (with citation)\n- Provide supporting details with evidence (with citations)\n- Address all sub-aspects of the query (each with citations)\n- Use proper citations for EVERY factual claim\n- Organize with bullet points or paragraphs as appropriate\n\n## EXAMPLE MULTI-SOURCE CITATION:\n\"Machine learning requires training data **[Doc: ML_Basics.pdf, Page: 12]** and can achieve 95% accuracy **[Doc: ML_Performance.pdf, Page: 8]** when properly configured **[Doc: ML_Best_Practices.pdf, Page: 22]**.\"\n\n## REMEMBER:\nYou have access to authoritative sources. Use them confidently with COMPLETE citations. Only claim 'not found' after exhaustive examination of all provided context.",
          "prompts": [
            {
              "content": "**Query Planning Analysis:**\n{Agent:Planner@content}\n\n=== RETRIEVED KNOWLEDGE BASE CONTEXT ===\n\n{Retrieval_Advanced@formalized_content}\n\n=== END OF CONTEXT ===\n\n**Original Question:** {sys.query}\n\n**Instructions:** \nThe retrieval system has gathered relevant documents based on the query plan above. These documents contain the information needed to answer the question comprehensively.\n\n1. Read through ALL retrieved context carefully\n2. Identify key information related to each aspect of the question\n3. Synthesize a complete answer that addresses all parts of the query\n4. CITE EVERY SOURCE using format: **[Doc: name, Page: X]**\n5. Include document name, page number, and section if available\n6. Use multiple citations when combining information from different sources\n7. Organize your response clearly\n\nProvide your comprehensive answer with complete citations:",
              "role": "user"
            }
          ],
          "max_tokens": 4096,
          "temperature": 0.4,
          "top_p": 0.3,
          "presence_penalty": 0.4,
          "frequency_penalty": 0.7,
          "output_structure": null,
          "cite": true,
          "visual_files_var": null,
          "function_name": "agent",
          "tools": [
            {
              "component_name": "Retrieval",
              "id": "Retrieval:AdvancedKBSearch",
              "name": "Retrieval_Advanced",
              "params": {
                "cross_languages": [],
                "kb_ids": [
                  "6f357bd7f45f11f085b53ae7a67b446b"
                ],
                "keywords_similarity_weight": 0.3,
                "meta_data_filter": {},
                "outputs": {
                  "chunks": {
                    "value": null
                  },
                  "metadata": {
                    "value": null
                  }
                },
                "rerank_id": "",
                "retrieval_from": "dataset",
                "similarity_threshold": 0.11,
                "toc_enhance": true,
                "top_k": 1024,
                "top_n": 10,
                "use_kg": true
              }
            }
          ],
          "mcp": [],
          "max_rounds": 1,
          "frequencyPenaltyEnabled": false,
          "maxTokensEnabled": false,
          "presencePenaltyEnabled": false,
          "temperatureEnabled": true,
          "topPEnabled": false
        }
      },
      "downstream": [
        "Message:ComplexOutput"
      ],
      "upstream": [
        "Agent:Planner"
      ]
    },
    "Message:ConversationalOutput": {
      "obj": {
        "component_name": "Message",
        "params": {
          "message_history_window_size": 13,
          "inputs": {},
          "outputs": {
            "content": {
              "type": "str",
              "value": null
            }
          },
          "description": "",
          "max_retries": 0,
          "delay_after_error": 2.0,
          "exception_method": null,
          "exception_default_value": null,
          "exception_goto": null,
          "debug_inputs": {},
          "content": [
            "{Agent:ConversationalSimple@content}"
          ],
          "stream": true,
          "output_format": null,
          "auto_play": false
        }
      },
      "downstream": [],
      "upstream": [
        "Agent:ConversationalSimple"
      ]
    },
    "Message:SimpleOutput": {
      "obj": {
        "component_name": "Message",
        "params": {
          "message_history_window_size": 13,
          "inputs": {},
          "outputs": {
            "content": {
              "type": "str",
              "value": null
            }
          },
          "description": "",
          "max_retries": 0,
          "delay_after_error": 2.0,
          "exception_method": null,
          "exception_default_value": null,
          "exception_goto": null,
          "debug_inputs": {},
          "content": [
            "{Agent:SimpleRetrieval@content}"
          ],
          "stream": true,
          "output_format": null,
          "auto_play": false
        }
      },
      "downstream": [],
      "upstream": [
        "Agent:SimpleRetrieval"
      ]
    },
    "Message:ComplexOutput": {
      "obj": {
        "component_name": "Message",
        "params": {
          "message_history_window_size": 13,
          "inputs": {},
          "outputs": {
            "content": {
              "type": "str",
              "value": null
            }
          },
          "description": "",
          "max_retries": 0,
          "delay_after_error": 2.0,
          "exception_method": null,
          "exception_default_value": null,
          "exception_goto": null,
          "debug_inputs": {},
          "content": [
            "{Agent:AdvancedRetrieval@content}"
          ],
          "stream": true,
          "output_format": null,
          "auto_play": false
        }
      },
      "downstream": [],
      "upstream": [
        "Agent:AdvancedRetrieval"
      ]
    }
  },
  "globals": {
    "sys.conversation_turns": 0,
    "sys.files": [],
    "sys.query": "",
    "sys.user_id": ""
  },
  "graph": {
    "nodes": [
      {
        "data": {
          "form": {
            "enablePrologue": true,
            "inputs": {},
            "mode": "conversational",
            "outputs": {},
            "prologue": "Hi! I'm your AI assistant with access to a knowledge base. Ask me anything!"
          },
          "label": "Begin",
          "name": "begin"
        },
        "id": "begin",
        "measured": {
          "height": 82,
          "width": 200
        },
        "position": {
          "x": -600,
          "y": 0
        },
        "sourcePosition": "right",
        "targetPosition": "left",
        "type": "beginNode"
      },
      {
        "data": {
          "form": {
            "items": [
              {
                "description": "Greetings, casual chat, thank yous, or questions that don't require knowledge retrieval. Examples: 'Hello', 'How are you?', 'Thanks!', 'What can you do?'",
                "examples": [
                  {
                    "value": "Hi there"
                  },
                  {
                    "value": "Thank you"
                  }
                ],
                "name": "Conversational",
                "uuid": "uuid-conversational-001"
              },
              {
                "description": "Straightforward factual questions answerable with specific information. Starts with 'What is', 'When is', 'Who is', 'Where is'. No comparison or complex reasoning needed.",
                "examples": [
                  {
                    "value": "What is machine learning?"
                  },
                  {
                    "value": "Who invented the telephone?"
                  }
                ],
                "name": "Simple_Lookup",
                "uuid": "uuid-simple-lookup-002"
              },
              {
                "description": "Complex queries requiring analysis, comparison, or synthesis across multiple sources. Includes 'How' or 'Why' questions, summaries, comparisons. Triggers comprehensive retrieval.",
                "examples": [
                  {
                    "value": "Compare supervised and unsupervised learning"
                  },
                  {
                    "value": "Why did the Roman Empire fall?"
                  }
                ],
                "name": "Complex_Analysis",
                "uuid": "uuid-complex-analysis-003"
              }
            ],
            "llm_id": "phi4:latest@Ollama",
            "message_history_window_size": 1,
            "outputs": {
              "category_name": {
                "type": "string"
              }
            },
            "parameter": "Precise",
            "query": "sys.query",
            "temperature": 0.1,
            "temperatureEnabled": false
          },
          "label": "Categorize",
          "name": "Query Router"
        },
        "id": "Categorize:QueryRouter",
        "measured": {
          "height": 186,
          "width": 200
        },
        "position": {
          "x": -300,
          "y": 0
        },
        "sourcePosition": "right",
        "targetPosition": "left",
        "type": "categorizeNode"
      },
      {
        "data": {
          "form": {
            "cite": false,
            "frequencyPenaltyEnabled": false,
            "frequency_penalty": 0.7,
            "llm_id": "llama3.2:latest@Ollama",
            "maxTokensEnabled": false,
            "max_retries": 1,
            "max_rounds": 1,
            "max_tokens": 512,
            "message_history_window_size": 12,
            "outputs": {
              "content": {
                "type": "string",
                "value": ""
              }
            },
            "presencePenaltyEnabled": false,
            "presence_penalty": 0.4,
            "prompts": [
              {
                "content": "{sys.query}",
                "role": "user"
              }
            ],
            "sys_prompt": "You are a friendly, helpful AI assistant. Answer conversational queries, greetings, and general questions directly without needing external knowledge. Be warm, concise, and engaging.",
            "temperature": 0.7,
            "temperatureEnabled": true,
            "tools": [],
            "topPEnabled": false,
            "top_p": 0.3
          },
          "label": "Agent",
          "name": "Conversational Agent"
        },
        "id": "Agent:ConversationalSimple",
        "measured": {
          "height": 90,
          "width": 200
        },
        "position": {
          "x": 0,
          "y": -150
        },
        "selected": false,
        "sourcePosition": "right",
        "targetPosition": "left",
        "type": "agentNode"
      },
      {
        "data": {
          "form": {
            "cite": true,
            "frequencyPenaltyEnabled": false,
            "frequency_penalty": 0.7,
            "llm_id": "qwen2.5:32b@Ollama",
            "maxTokensEnabled": false,
            "max_retries": 2,
            "max_rounds": 1,
            "max_tokens": 2048,
            "message_history_window_size": 12,
            "outputs": {
              "content": {
                "type": "string",
                "value": ""
              }
            },
            "presencePenaltyEnabled": false,
            "presence_penalty": 0.4,
            "prompts": [
              {
                "content": "=== RETRIEVED DOCUMENTS FROM KNOWLEDGE BASE ===\n{Retrieval_Simple@formalized_content}\n=== END OF RETRIEVED DOCUMENTS ===\n>>> CRITICAL: You have NO knowledge except what appears above in RETRIEVED DOCUMENTS <\n**User Question:** {sys.query}\n**Your Task:**\n1. Search ONLY the retrieved documents above for the answer\n2. Extract facts ONLY from the retrieved content\n3. Use format: **[Doc: document_name, Page: X]** for citations\n4. Cite EVERY fact immediately after stating it\n5. If not in retrieved documents above, say: \"This information is not in my knowledge base\"\n**Answer using ONLY the retrieved documents:**",
                "role": "user"
              }
            ],
            "sys_prompt": "You are a precise Retrieval Assistant. Your sole objective is to answer the user's question using ONLY the provided context.\n### CONSTRAINTS:\n1. **Source Grounding:** If the answer isn't in the context, state exactly what is missing rather than saying \"I don't know.\"\n2. **Directness:** Do not use filler phrases like \"Based on the documents provided...\" Jump straight to the facts.\n3. **Citation Format:** Every factual claim must be followed by: **[Doc: document_name, Page: X]**.\n4. **No Assumptions:** Do not use outside knowledge. If the context says the sky is green, the sky is green.\n### TONE:\nProfessional, objective, and concise.",
            "temperature": 0.4,
            "temperatureEnabled": true,
            "tools": [
              {
                "component_name": "Retrieval",
                "id": "Retrieval:SimpleKBSearch",
                "name": "Retrieval_Simple",
                "params": {
                  "cross_languages": [],
                  "kb_ids": [
                    "6f357bd7f45f11f085b53ae7a67b446b"
                  ],
                  "keywords_similarity_weight": 0.3,
                  "meta_data_filter": {},
                  "outputs": {
                    "chunks": {},
                    "metadata": {}
                  },
                  "rerank_id": "",
                  "retrieval_from": "dataset",
                  "similarity_threshold": 0.1,
                  "toc_enhance": true,
                  "top_k": 1024,
                  "top_n": 8,
                  "use_kg": true
                }
              }
            ],
            "topPEnabled": false,
            "top_p": 0.3
          },
          "label": "Agent",
          "name": "Simple Lookup Agent"
        },
        "dragging": false,
        "id": "Agent:SimpleRetrieval",
        "measured": {
          "height": 90,
          "width": 200
        },
        "position": {
          "x": 31.132788500612833,
          "y": 32.82328910311017
        },
        "selected": false,
        "sourcePosition": "right",
        "targetPosition": "left",
        "type": "agentNode"
      },
      {
        "data": {
          "form": {
            "cite": false,
            "frequencyPenaltyEnabled": false,
            "frequency_penalty": 0.7,
            "llm_id": "phi4:latest@Ollama",
            "maxTokensEnabled": false,
            "max_retries": 1,
            "max_rounds": 1,
            "max_tokens": 512,
            "message_history_window_size": 1,
            "outputs": {
              "content": {
                "type": "string",
                "value": ""
              }
            },
            "presencePenaltyEnabled": false,
            "presence_penalty": 0.4,
            "prompts": [
              {
                "content": "Analyze this query and create a retrieval plan:\n\n**Query:** {sys.query}\n\nProvide:\n1. 1-3 focused sub-questions (if query is multi-faceted)\n2. Key search terms and entities\n3. Retrieval strategy recommendation\n\nBe concise - 3-4 sentences total.",
                "role": "user"
              }
            ],
            "sys_prompt": "You are a query planning agent for a RAG system. Break down complex queries into focused sub-questions and determine the optimal retrieval strategy.\n\nYour output helps the retrieval system find the most relevant information.",
            "temperature": 0.2,
            "temperatureEnabled": true,
            "tools": [],
            "topPEnabled": false,
            "top_p": 0.3
          },
          "label": "Agent",
          "name": "Query Planner"
        },
        "id": "Agent:Planner",
        "measured": {
          "height": 90,
          "width": 200
        },
        "position": {
          "x": 0,
          "y": 250
        },
        "selected": false,
        "sourcePosition": "right",
        "targetPosition": "left",
        "type": "agentNode"
      },
      {
        "data": {
          "form": {
            "cite": true,
            "frequencyPenaltyEnabled": false,
            "frequency_penalty": 0.7,
            "llm_id": "qwen2.5:32b@Ollama",
            "maxTokensEnabled": false,
            "max_retries": 2,
            "max_rounds": 1,
            "max_tokens": 4096,
            "message_history_window_size": 12,
            "outputs": {
              "content": {
                "type": "string",
                "value": ""
              }
            },
            "presencePenaltyEnabled": false,
            "presence_penalty": 0.4,
            "prompts": [
              {
                "content": "**Query Planning Analysis:**\n{Agent:Planner@content}\n\n=== RETRIEVED KNOWLEDGE BASE CONTEXT ===\n\n{Retrieval_Advanced@formalized_content}\n\n=== END OF CONTEXT ===\n\n**Original Question:** {sys.query}\n\n**Instructions:** \nThe retrieval system has gathered relevant documents based on the query plan above. These documents contain the information needed to answer the question comprehensively.\n\n1. Read through ALL retrieved context carefully\n2. Identify key information related to each aspect of the question\n3. Synthesize a complete answer that addresses all parts of the query\n4. CITE EVERY SOURCE using format: **[Doc: name, Page: X]**\n5. Include document name, page number, and section if available\n6. Use multiple citations when combining information from different sources\n7. Organize your response clearly\n\nProvide your comprehensive answer with complete citations:",
                "role": "user"
              }
            ],
            "sys_prompt": "You are an expert research assistant with access to a comprehensive knowledge base.\n\n## YOUR EXPERTISE:\nYou excel at answering complex, multi-faceted questions by synthesizing information from multiple sources with DETAILED CITATIONS.\n\n## CRITICAL RULES:\n1. The retrieval system has found relevant documents - TRUST and USE them\n2. Information may be distributed across multiple chunks - COMBINE them intelligently\n3. Look for connections, patterns, and relationships in the retrieved content\n4. The answer IS in the context - it may require synthesis but it's there\n5. Use semantic understanding - answers may be phrased differently than the question\n6. Be thorough - complex questions deserve comprehensive answers\n\n## CITATION FORMAT (MANDATORY):\nFor EVERY factual statement, use this format:\n- **[Doc: {document_name}, Page: {page_number}, Section: {section_name}]**\n- OR **[Source: {chunk_id}]** if full metadata unavailable\n- Place citations immediately after each claim\n- Use multiple citations when synthesizing from multiple sources\n- Include as much source metadata as available\n\n## ANSWER STRUCTURE:\n- Start with a direct answer to the main question (with citation)\n- Provide supporting details with evidence (with citations)\n- Address all sub-aspects of the query (each with citations)\n- Use proper citations for EVERY factual claim\n- Organize with bullet points or paragraphs as appropriate\n\n## EXAMPLE MULTI-SOURCE CITATION:\n\"Machine learning requires training data **[Doc: ML_Basics.pdf, Page: 12]** and can achieve 95% accuracy **[Doc: ML_Performance.pdf, Page: 8]** when properly configured **[Doc: ML_Best_Practices.pdf, Page: 22]**.\"\n\n## REMEMBER:\nYou have access to authoritative sources. Use them confidently with COMPLETE citations. Only claim 'not found' after exhaustive examination of all provided context.",
            "temperature": 0.4,
            "temperatureEnabled": true,
            "tools": [
              {
                "component_name": "Retrieval",
                "id": "Retrieval:AdvancedKBSearch",
                "name": "Retrieval_Advanced",
                "params": {
                  "cross_languages": [],
                  "kb_ids": [
                    "6f357bd7f45f11f085b53ae7a67b446b"
                  ],
                  "keywords_similarity_weight": 0.3,
                  "meta_data_filter": {},
                  "outputs": {
                    "chunks": {},
                    "metadata": {}
                  },
                  "rerank_id": "",
                  "retrieval_from": "dataset",
                  "similarity_threshold": 0.11,
                  "toc_enhance": true,
                  "top_k": 1024,
                  "top_n": 10,
                  "use_kg": true
                }
              }
            ],
            "topPEnabled": false,
            "top_p": 0.3
          },
          "label": "Agent",
          "name": "Advanced Retrieval Agent"
        },
        "id": "Agent:AdvancedRetrieval",
        "measured": {
          "height": 90,
          "width": 200
        },
        "position": {
          "x": 300,
          "y": 250
        },
        "selected": false,
        "sourcePosition": "right",
        "targetPosition": "left",
        "type": "agentNode"
      },
      {
        "data": {
          "form": {
            "content": [
              "{Agent:ConversationalSimple@content}"
            ]
          },
          "label": "Message",
          "name": "Conversational Output"
        },
        "id": "Message:ConversationalOutput",
        "measured": {
          "height": 86,
          "width": 200
        },
        "position": {
          "x": 300,
          "y": -150
        },
        "sourcePosition": "right",
        "targetPosition": "left",
        "type": "messageNode"
      },
      {
        "data": {
          "form": {
            "content": [
              "{Agent:SimpleRetrieval@content}"
            ]
          },
          "label": "Message",
          "name": "Simple Lookup Output"
        },
        "id": "Message:SimpleOutput",
        "measured": {
          "height": 86,
          "width": 200
        },
        "position": {
          "x": 300,
          "y": 50
        },
        "sourcePosition": "right",
        "targetPosition": "left",
        "type": "messageNode"
      },
      {
        "data": {
          "form": {
            "content": [
              "{Agent:AdvancedRetrieval@content}"
            ]
          },
          "label": "Message",
          "name": "Complex Analysis Output"
        },
        "id": "Message:ComplexOutput",
        "measured": {
          "height": 86,
          "width": 200
        },
        "position": {
          "x": 600,
          "y": 250
        },
        "sourcePosition": "right",
        "targetPosition": "left",
        "type": "messageNode"
      },
      {
        "data": {
          "form": {
            "description": "This is an agent for a specific task.",
            "user_prompt": "This is the order you need to send to the agent."
          },
          "label": "Tool",
          "name": "flow.tool_0"
        },
        "id": "Tool:PetiteBroomsDesign",
        "measured": {
          "height": 50,
          "width": 200
        },
        "position": {
          "x": -50.86721149938717,
          "y": 172.82328910311017
        },
        "selected": false,
        "sourcePosition": "right",
        "targetPosition": "left",
        "type": "toolNode"
      },
      {
        "data": {
          "form": {
            "description": "This is an agent for a specific task.",
            "user_prompt": "This is the order you need to send to the agent."
          },
          "label": "Tool",
          "name": "flow.tool_1"
        },
        "id": "Tool:BlueEmusWorry",
        "measured": {
          "height": 50,
          "width": 200
        },
        "position": {
          "x": 218,
          "y": 390
        },
        "selected": true,
        "sourcePosition": "right",
        "targetPosition": "left",
        "type": "toolNode"
      }
    ],
    "edges": [
      {
        "data": {
          "isHovered": false
        },
        "id": "e1",
        "source": "begin",
        "sourceHandle": "start",
        "target": "Categorize:QueryRouter",
        "targetHandle": "end"
      },
      {
        "data": {
          "isHovered": false
        },
        "id": "e2-conversational",
        "source": "Categorize:QueryRouter",
        "sourceHandle": "uuid-conversational-001",
        "target": "Agent:ConversationalSimple",
        "targetHandle": "end"
      },
      {
        "data": {
          "isHovered": false
        },
        "id": "e3-simple",
        "source": "Categorize:QueryRouter",
        "sourceHandle": "uuid-simple-lookup-002",
        "target": "Agent:SimpleRetrieval",
        "targetHandle": "end"
      },
      {
        "data": {
          "isHovered": false
        },
        "id": "e4-complex",
        "source": "Categorize:QueryRouter",
        "sourceHandle": "uuid-complex-analysis-003",
        "target": "Agent:Planner",
        "targetHandle": "end"
      },
      {
        "data": {
          "isHovered": false
        },
        "id": "e5",
        "source": "Agent:Planner",
        "sourceHandle": "start",
        "target": "Agent:AdvancedRetrieval",
        "targetHandle": "end"
      },
      {
        "data": {
          "isHovered": false
        },
        "id": "e6-conv-output",
        "source": "Agent:ConversationalSimple",
        "sourceHandle": "start",
        "target": "Message:ConversationalOutput",
        "targetHandle": "end"
      },
      {
        "data": {
          "isHovered": false
        },
        "id": "e7-simple-output",
        "source": "Agent:SimpleRetrieval",
        "sourceHandle": "start",
        "target": "Message:SimpleOutput",
        "targetHandle": "end"
      },
      {
        "data": {
          "isHovered": false
        },
        "id": "e8-complex-output",
        "source": "Agent:AdvancedRetrieval",
        "sourceHandle": "start",
        "target": "Message:ComplexOutput",
        "targetHandle": "end"
      },
      {
        "data": {
          "isHovered": false
        },
        "id": "xy-edge__Agent:SimpleRetrievaltool-Tool:PetiteBroomsDesignend",
        "source": "Agent:SimpleRetrieval",
        "sourceHandle": "tool",
        "target": "Tool:PetiteBroomsDesign",
        "targetHandle": "end"
      },
      {
        "data": {
          "isHovered": false
        },
        "id": "xy-edge__Agent:AdvancedRetrievaltool-Tool:BlueEmusWorryend",
        "source": "Agent:AdvancedRetrieval",
        "sourceHandle": "tool",
        "target": "Tool:BlueEmusWorry",
        "targetHandle": "end"
      }
    ]
  },
  "history": [],
  "memory": [],
  "messages": [],
  "path": [],
  "retrieval": [],
  "task_id": "2436a9dd001211f1b3841e210f381e29",
  "variables": {}
}
